{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700, 92)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv('./features_reduced_imputed.csv')\n",
    "x.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. binary column중 unbalance한 Feature 삭제 therehold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nr_01 1696 4 99.76470588235294 0.2352941176470588\n",
      "nr_04 1671 29 98.29411764705883 1.7058823529411766\n",
      "nr_07 1699 1 99.94117647058823 0.0588235294117647\n",
      "nr_08 1696 4 99.76470588235294 0.2352941176470588\n",
      "np_01 1698 2 99.88235294117646 0.1176470588235294\n",
      "np_04 1697 3 99.82352941176471 0.17647058823529413\n",
      "np_05 1689 11 99.3529411764706 0.6470588235294118\n",
      "np_07 1699 1 99.94117647058823 0.0588235294117647\n",
      "endocr_03 1687 13 99.23529411764706 0.7647058823529412\n",
      "zab_leg_04 1691 9 99.47058823529412 0.5294117647058824\n",
      "SVT_POST 1692 8 99.52941176470588 0.4705882352941176\n",
      "GT_POST 1692 8 99.52941176470588 0.4705882352941176\n",
      "FIB_G_POST 1685 15 99.11764705882354 0.8823529411764706\n",
      "n_r_ecg_p_08 1696 4 99.76470588235294 0.2352941176470588\n",
      "n_r_ecg_p_09 1698 2 99.88235294117646 0.1176470588235294\n",
      "n_r_ecg_p_10 1698 2 99.88235294117646 0.1176470588235294\n",
      "n_p_ecg_p_01 1698 2 99.88235294117646 0.1176470588235294\n",
      "fibr_ter_05 1696 4 99.76470588235294 0.2352941176470588\n",
      "fibr_ter_07 1694 6 99.6470588235294 0.35294117647058826\n",
      "fibr_ter_08 1698 2 99.88235294117646 0.1176470588235294\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "binary_column_info = {}\n",
    "\n",
    "# 각 컬럼 확인\n",
    "for column in x.columns:\n",
    "    # 유일한 값들 확인\n",
    "    unique_values = x[column].dropna().unique()\n",
    "    \n",
    "        # 0과 1만 있는지 확인\n",
    "    if set(unique_values) <= {0, 1}:\n",
    "        count_0 = (x[column] == 0).sum()\n",
    "        count_1 = (x[column] == 1).sum()\n",
    "        total_count = count_0 + count_1\n",
    "        percent_0 = (count_0 / total_count) * 100\n",
    "        percent_1 = (count_1 / total_count) * 100\n",
    "        binary_column_info[column] = {\n",
    "            '0 count': count_0, \n",
    "            '1 count': count_1,\n",
    "            '0 percent': percent_0,\n",
    "            '1 percent': percent_1\n",
    "        }\n",
    "\n",
    "cnt = 0\n",
    "for column, counts in binary_column_info.items():\n",
    "    \n",
    "    if(counts['1 percent'] <= 2):\n",
    "        cnt +=1\n",
    "        print(column, counts['0 count'], counts['1 count'], counts['0 percent'], counts['1 percent'])\n",
    "    '''\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"  0 count: {counts['0 count']}, 1 count: {counts['1 count']}\")\n",
    "    print(f\"  0 percent: {counts['0 percent']:.2f}%, 1 percent: {counts['1 percent']:.2f}%\")\n",
    "    '''\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. VAE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m vae \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mModel(inputs, outputs)\n\u001b[1;32m     43\u001b[0m \u001b[39m# Define the loss\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m reconstruction_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlosses\u001b[39m.\u001b[39;49mmse(inputs, outputs)\n\u001b[1;32m     45\u001b[0m reconstruction_loss \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m input_dim\n\u001b[1;32m     46\u001b[0m kl_loss \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m z_log_var \u001b[39m-\u001b[39m K\u001b[39m.\u001b[39msquare(z_mean) \u001b[39m-\u001b[39m K\u001b[39m.\u001b[39mexp(z_log_var)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/losses/losses.py:1151\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[39m@keras_export\u001b[39m(\n\u001b[1;32m   1119\u001b[0m     [\n\u001b[1;32m   1120\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mkeras.metrics.mean_squared_error\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1128\u001b[0m )\n\u001b[1;32m   1129\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_squared_error\u001b[39m(y_true, y_pred):\n\u001b[1;32m   1130\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Computes the mean squared error between labels and predictions.\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \n\u001b[1;32m   1132\u001b[0m \u001b[39m    Formula:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[39m        Mean squared error values with shape = `[batch_size, d0, .. dN-1]`.\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1151\u001b[0m     y_pred \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(y_pred)\n\u001b[1;32m   1152\u001b[0m     y_true \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(y_true, dtype\u001b[39m=\u001b[39my_pred\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   1153\u001b[0m     y_true, y_pred \u001b[39m=\u001b[39m squeeze_or_expand_to_same_rank(y_true, y_pred)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/ops/core.py:493\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.ops.convert_to_tensor\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    475\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor\u001b[39m(x, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sparse\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    476\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert a NumPy array to a tensor.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \n\u001b[1;32m    478\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39m    >>> y = keras.ops.convert_to_tensor(x)\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mconvert_to_tensor(x, dtype\u001b[39m=\u001b[39;49mdtype, sparse\u001b[39m=\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py:115\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    113\u001b[0m         x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m    114\u001b[0m         \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcast(x, dtype)\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mconvert_to_tensor(x, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    116\u001b[0m \u001b[39melif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcast(x, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/backend/common/keras_tensor.py:92\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__tf_tensor__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mused when constructing Keras Functional models \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand `keras.operations`). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are likely doing something like:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mx = Input(...)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtf_fn(x)  # Invalid.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclass MyLayer(Layer):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m    def call(self, x):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m        return tf_fn(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mx = MyLayer()(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = './features_reduced_imputed.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "data.head()\n",
    "\n",
    "# Define the encoder\n",
    "input_dim = data.shape[1]\n",
    "latent_dim = 2  # You can adjust the dimensionality of the latent space\n",
    "\n",
    "inputs = layers.Input(shape=(input_dim,))\n",
    "h = layers.Dense(64, activation='relu')(inputs)\n",
    "h = layers.Dense(32, activation='relu')(h)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_var = layers.Dense(latent_dim)(h)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.keras.backend.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Define the decoder\n",
    "decoder_h = layers.Dense(32, activation='relu')\n",
    "decoder_h2 = layers.Dense(64, activation='relu')\n",
    "decoder_mean = layers.Dense(input_dim, activation='sigmoid')\n",
    "\n",
    "h_decoded = decoder_h(z)\n",
    "h_decoded = decoder_h2(h_decoded)\n",
    "outputs = decoder_mean(h_decoded)\n",
    "\n",
    "# Define the VAE model\n",
    "vae = models.Model(inputs, outputs)\n",
    "\n",
    "# Define the loss\n",
    "reconstruction_loss = tf.keras.losses.mse(inputs, outputs)\n",
    "reconstruction_loss *= input_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
