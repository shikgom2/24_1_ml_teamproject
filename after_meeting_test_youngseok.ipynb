{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700, 99)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv('./data/3.remove_unbalance_missing_corr_data/features_remove_missing_corr_knn.csv')\n",
    "#x.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. binary column중 unbalance한 Feature 삭제 therehold = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX is balanced. 635 1065\n",
      "SIM_GIPERT is balanced. 1643 57\n",
      "nr_11 is balanced. 1658 42\n",
      "nr_01 is unbalanced. 1696 4\n",
      "nr_02 is balanced. 1681 19\n",
      "nr_03 is balanced. 1665 35\n",
      "nr_04 is balanced. 1671 29\n",
      "nr_07 is unbalanced. 1699 1\n",
      "nr_08 is unbalanced. 1696 4\n",
      "np_01 is unbalanced. 1698 2\n",
      "np_04 is unbalanced. 1697 3\n",
      "np_05 is unbalanced. 1689 11\n",
      "np_07 is unbalanced. 1699 1\n",
      "np_08 is unbalanced. 1694 6\n",
      "np_09 is unbalanced. 1698 2\n",
      "np_10 is unbalanced. 1697 3\n",
      "endocr_01 is balanced. 1472 228\n",
      "endocr_02 is balanced. 1658 42\n",
      "endocr_03 is unbalanced. 1687 13\n",
      "zab_leg_01 is balanced. 1566 134\n",
      "zab_leg_02 is balanced. 1579 121\n",
      "zab_leg_03 is balanced. 1663 37\n",
      "zab_leg_04 is unbalanced. 1691 9\n",
      "zab_leg_06 is balanced. 1678 22\n",
      "O_L_POST is balanced. 1590 110\n",
      "K_SH_POST is balanced. 1653 47\n",
      "MP_TP_POST is balanced. 1586 114\n",
      "SVT_POST is unbalanced. 1692 8\n",
      "GT_POST is unbalanced. 1692 8\n",
      "FIB_G_POST is unbalanced. 1685 15\n",
      "IM_PG_P is balanced. 1650 50\n",
      "ritm_ecg_p_01 is balanced. 555 1145\n",
      "ritm_ecg_p_04 is balanced. 1677 23\n",
      "ritm_ecg_p_06 is unbalanced. 1699 1\n",
      "ritm_ecg_p_08 is balanced. 1654 46\n",
      "n_r_ecg_p_01 is balanced. 1642 58\n",
      "n_r_ecg_p_02 is unbalanced. 1692 8\n",
      "n_r_ecg_p_03 is balanced. 1493 207\n",
      "n_r_ecg_p_04 is balanced. 1631 69\n",
      "n_r_ecg_p_05 is balanced. 1630 70\n",
      "n_r_ecg_p_06 is balanced. 1668 32\n",
      "n_r_ecg_p_08 is unbalanced. 1696 4\n",
      "n_r_ecg_p_09 is unbalanced. 1698 2\n",
      "n_r_ecg_p_10 is unbalanced. 1698 2\n",
      "n_p_ecg_p_01 is unbalanced. 1698 2\n",
      "n_p_ecg_p_03 is balanced. 1668 32\n",
      "n_p_ecg_p_04 is unbalanced. 1695 5\n",
      "n_p_ecg_p_05 is unbalanced. 1698 2\n",
      "n_p_ecg_p_06 is balanced. 1672 28\n",
      "n_p_ecg_p_07 is balanced. 1598 102\n",
      "n_p_ecg_p_08 is unbalanced. 1693 7\n",
      "n_p_ecg_p_09 is unbalanced. 1690 10\n",
      "n_p_ecg_p_10 is balanced. 1666 34\n",
      "n_p_ecg_p_11 is balanced. 1672 28\n",
      "n_p_ecg_p_12 is balanced. 1622 78\n",
      "fibr_ter_01 is unbalanced. 1687 13\n",
      "fibr_ter_02 is unbalanced. 1684 16\n",
      "fibr_ter_03 is balanced. 1632 68\n",
      "fibr_ter_05 is unbalanced. 1696 4\n",
      "fibr_ter_06 is unbalanced. 1691 9\n",
      "fibr_ter_07 is unbalanced. 1694 6\n",
      "fibr_ter_08 is unbalanced. 1698 2\n",
      "GIPO_K is balanced. 1047 653\n",
      "GIPER_NA is balanced. 1670 30\n",
      "NITR_S is balanced. 1505 195\n",
      "LID_S_n is balanced. 1221 479\n",
      "B_BLOK_S_n is balanced. 1485 215\n",
      "ANT_CA_S_n is balanced. 564 1136\n",
      "GEPAR_S_n is balanced. 485 1215\n",
      "ASP_S_n is balanced. 433 1267\n",
      "TIKL_S_n is balanced. 1670 30\n",
      "TRENT_S_n is balanced. 1358 342\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "binary_column_info = {}\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for column in x.columns:\n",
    "    # 유일한 값들 확인\n",
    "    unique_values = x[column].dropna().unique()\n",
    "    \n",
    "    # 0과 1만 있는지 확인\n",
    "    if set(unique_values) <= {0, 1}:\n",
    "        count_0 = (x[column] == 0).sum()\n",
    "        count_1 = (x[column] == 1).sum()\n",
    "        total_count = count_0 + count_1\n",
    "        percent_0 = (count_0 / total_count) * 100\n",
    "        percent_1 = (count_1 / total_count) * 100\n",
    "        binary_column_info[column] = {\n",
    "            '0 count': count_0, \n",
    "            '1 count': count_1,\n",
    "            '0 percent': percent_0,\n",
    "            '1 percent': percent_1\n",
    "        }\n",
    "\n",
    "li = []\n",
    "for column, counts in binary_column_info.items():\n",
    "\n",
    "    if(counts['1 percent'] <= 1):\n",
    "        print(column, \"is unbalanced.\", counts['0 count'], counts['1 count'])\n",
    "        cnt +=1\n",
    "        li.append(column)\n",
    "    else:\n",
    "        print(column, \"is balanced.\", counts['0 count'], counts['1 count'])\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1700, 68)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.drop(columns=li)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv('./data/3.remove_unbalance_missing_corr_data/1_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. VAE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m vae \u001b[39m=\u001b[39m Model(input_img, output_combined, name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvae\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[39m# VAE 손실 함수 정의\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m reconstruction_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlosses\u001b[39m.\u001b[39;49mbinary_crossentropy(input_img, output_combined)\n\u001b[1;32m     46\u001b[0m reconstruction_loss \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreduce_sum(reconstruction_loss, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m kl_loss \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m z_log_var \u001b[39m-\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39msquare(z_mean) \u001b[39m-\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mexp(z_log_var)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/losses/losses.py:1767\u001b[0m, in \u001b[0;36mbinary_crossentropy\u001b[0;34m(y_true, y_pred, from_logits, label_smoothing, axis)\u001b[0m\n\u001b[1;32m   1733\u001b[0m \u001b[39m@keras_export\u001b[39m(\n\u001b[1;32m   1734\u001b[0m     [\n\u001b[1;32m   1735\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mkeras.metrics.binary_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1740\u001b[0m     y_true, y_pred, from_logits\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, label_smoothing\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   1741\u001b[0m ):\n\u001b[1;32m   1742\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Computes the binary crossentropy loss.\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \n\u001b[1;32m   1744\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[39m    array([0.916 , 0.714], dtype=float32)\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1767\u001b[0m     y_pred \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(y_pred)\n\u001b[1;32m   1768\u001b[0m     y_true \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mcast(y_true, y_pred\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   1770\u001b[0m     \u001b[39mif\u001b[39;00m label_smoothing:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/ops/core.py:493\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.ops.convert_to_tensor\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    475\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_tensor\u001b[39m(x, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sparse\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    476\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert a NumPy array to a tensor.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \n\u001b[1;32m    478\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39m    >>> y = keras.ops.convert_to_tensor(x)\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 493\u001b[0m     \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mconvert_to_tensor(x, dtype\u001b[39m=\u001b[39;49mdtype, sparse\u001b[39m=\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/backend/tensorflow/core.py:115\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(x, dtype, sparse)\u001b[0m\n\u001b[1;32m    113\u001b[0m         x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m    114\u001b[0m         \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcast(x, dtype)\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mconvert_to_tensor(x, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    116\u001b[0m \u001b[39melif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mcast(x, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/keras/src/backend/common/keras_tensor.py:92\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__tf_tensor__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     93\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mused when constructing Keras Functional models \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mand `keras.operations`). \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou are likely doing something like:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mx = Input(...)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtf_fn(x)  # Invalid.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mclass MyLayer(Layer):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m    def call(self, x):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m        return tf_fn(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mx = MyLayer()(x)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m```\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "file_path = './1_1.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(data.head())\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.drop(columns=['Unnamed: 0']))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_val = train_test_split(data_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the encoder\n",
    "input_dim = x_train.shape[1]\n",
    "latent_dim = 2  # You can adjust the dimensionality of the latent space\n",
    "\n",
    "inputs = layers.Input(shape=(input_dim,))\n",
    "h = layers.Dense(64, activation='relu')(inputs)\n",
    "h = layers.Dense(32, activation='relu')(h)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_var = layers.Dense(latent_dim)(h)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.keras.backend.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# Define the decoder\n",
    "decoder_input = layers.Input(shape=(latent_dim,))\n",
    "decoder_h = layers.Dense(32, activation='relu')\n",
    "decoder_h2 = layers.Dense(64, activation='relu')\n",
    "decoder_mean = layers.Dense(input_dim, activation='sigmoid')\n",
    "\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_h_decoded = decoder_h2(_h_decoded)\n",
    "_outputs = decoder_mean(_h_decoded)\n",
    "\n",
    "decoder = models.Model(decoder_input, _outputs)\n",
    "\n",
    "# Define the VAE model\n",
    "h_decoded = decoder_h(z)\n",
    "h_decoded = decoder_h2(h_decoded)\n",
    "outputs = decoder_mean(h_decoded)\n",
    "vae = models.Model(inputs, outputs)\n",
    "\n",
    "# Define the loss\n",
    "reconstruction_loss = tf.keras.losses.mse(inputs, outputs)\n",
    "reconstruction_loss *= input_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "# Train the VAE model\n",
    "vae.fit(x_train, epochs=50, batch_size=32, validation_data=(x_val, None))\n",
    "\n",
    "# Generate new samples using the trained VAE\n",
    "def generate_samples(decoder, num_samples, latent_dim):\n",
    "    z_sample = np.random.normal(size=(num_samples, latent_dim))\n",
    "    generated_data = decoder.predict(z_sample)\n",
    "    return scaler.inverse_transform(generated_data)\n",
    "\n",
    "# Generate 100 new samples\n",
    "new_samples = generate_samples(decoder, 10, latent_dim)\n",
    "\n",
    "# Convert generated samples to DataFrame and round all values to integers\n",
    "new_samples_df = pd.DataFrame(new_samples, columns=data.columns[1:])\n",
    "#new_samples_df = new_samples_df.round(1)\n",
    "\n",
    "# Display the generated samples\n",
    "print(new_samples_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE [61.862152 61.904064 61.873535 61.8622   61.88735  61.86219  62.29251\n",
      " 61.872353 61.862274 61.862232]\n",
      "SEX [0.62647057 0.6264798  0.6264786  0.6264807  0.6273904  0.6264753 ]\n",
      "INF_ANAM [0.5554382  0.56035745 0.56237835 0.5555472  0.5624952  0.555519\n",
      " 0.60098267 0.5607117  0.5557131  0.5556157 ]\n",
      "IBS_POST [1.1676898 1.177472  1.1714579 1.1677295 1.1740502 1.1677223 1.2279601\n",
      " 1.1714482 1.1677824 1.1677508]\n",
      "SIM_GIPERT [0.03352957 0.0335954  0.03359849 0.0335298  0.0336033  0.03352977\n",
      " 0.03554852 0.03359427 0.03353011 0.03352992]\n",
      "ZSN_A [0.19178294 0.19483143 0.19401135 0.19180085 0.19538674 0.19179365\n",
      " 0.21972127 0.19313085 0.19183792 0.19181687]\n",
      "nr_11 [0.02470591 0.02473683 0.02472922 0.02470594 0.0247322  0.02470592\n",
      " 0.02584688 0.02472484 0.02470601 0.02470597]\n",
      "nr_02 [0.01117648 0.01119135 0.01118796 0.01117649 0.01119956 0.01117649\n",
      " 0.01187023 0.01118534 0.01117652 0.0111765 ]\n",
      "nr_03 [0.02058899 0.02081238 0.02075322 0.02058991 0.02079522 0.02058982\n",
      " 0.0244072  0.02075441 0.02059102 0.02059035]\n",
      "nr_04 [0.01707719 0.01889387 0.0180377  0.01709191 0.01827713 0.01709061\n",
      " 0.02829297 0.01815072 0.01710585 0.01709781]\n",
      "endocr_01 [0.13416615 0.13667941 0.1366619  0.13420418 0.13681042 0.13419554\n",
      " 0.15610197 0.13619864 0.1342548  0.13422632]\n",
      "endocr_02 [0.02470589 0.02472172 0.02471464 0.0247059  0.02471772 0.02541381\n",
      " 0.02471217 0.02470591 0.0247059 ]\n",
      "zab_leg_01 [0.08000004 0.08014601 0.08005009 0.08000011 0.08007447 0.08000009\n",
      " 0.08354428 0.08004207 0.08000027 0.08000015]\n",
      "zab_leg_02 [0.07118257 0.07181512 0.0718658  0.0711887  0.07189841 0.07118772\n",
      " 0.0802618  0.07169726 0.07119616 0.07119195]\n",
      "zab_leg_03 [0.02176474 0.02180433 0.02178091 0.02176474 0.02178677 0.02176473\n",
      " 0.02304543 0.02178063 0.02176477 0.02176475]\n",
      "zab_leg_06 [0.01294118 0.01294606 0.01294359 0.01294426 0.0133153  0.01294352\n",
      " 0.01294119 0.01294118]\n",
      "O_L_POST [0.06474879 0.06703202 0.06694829 0.06478121 0.06844371 0.06476694\n",
      " 0.08102103 0.06605907 0.06484473 0.06481044]\n",
      "K_SH_POST [0.02705886 0.02710824 0.02709256 0.02705892 0.02710214 0.02882509\n",
      " 0.02708673 0.02705902 0.02705896]\n",
      "ant_im [1.5576988 1.5651863 1.5632585 1.5577499 1.5641593 1.5577384 1.6381831\n",
      " 1.56226   1.5578233 1.5577807]\n",
      "lat_im [0.8529423  0.85469455 0.8534702  0.852944   0.8539051  0.8529435\n",
      " 0.8747314  0.8533386  0.85294706 0.85294527]\n",
      "inf_im [1.0117804 1.0132588 1.0139536 1.0117972 1.0130275 1.0117947 1.0391722\n",
      " 1.0138856 1.011819  1.011806 ]\n",
      "post_im [0.2541177  0.25430527 0.25420427 0.25411776 0.25425553 0.26033825\n",
      " 0.2541813  0.25411803 0.2541179 ]\n",
      "IM_PG_P [0.02941343 0.02972433 0.02969345 0.02941529 0.02971346 0.0294148\n",
      " 0.03389983 0.02963049 0.02941842 0.02941656]\n",
      "ritm_ecg_p_04 [0.01353086 0.0138203  0.01377406 0.01353243 0.01386746 0.01353185\n",
      " 0.01701835 0.01368634 0.01353573 0.01353378]\n",
      "ritm_ecg_p_08 [0.02705883 0.02708621 0.02707102 0.02705884 0.02707676 0.02705885\n",
      " 0.02811645 0.02706604 0.02705886 0.02705885]\n",
      "n_r_ecg_p_01 [0.03411766 0.03413134 0.03413098 0.03411767 0.03413999 0.03411767\n",
      " 0.0349233  0.03412516 0.03411768]\n",
      "n_r_ecg_p_03 [0.12176739 0.12282499 0.12228005 0.12177053 0.12247363 0.12176988\n",
      " 0.13334772 0.12225494 0.12177495 0.12177243]\n",
      "n_r_ecg_p_04 [0.04058824 0.04063711 0.04061018 0.04058827 0.04063261 0.04058826\n",
      " 0.04223591 0.04060145 0.04058832 0.04058828]\n",
      "n_r_ecg_p_05 [0.04119041 0.04231163 0.04218166 0.04120248 0.04218311 0.04119933\n",
      " 0.05123722 0.04198308 0.04122162 0.04121027]\n",
      "n_r_ecg_p_06 [0.01884081 0.01956951 0.01966431 0.01885427 0.01945597 0.01885288\n",
      " 0.02577492 0.01969538 0.0188688  0.01885999]\n",
      "n_p_ecg_p_03 [0.01882361 0.01885075 0.01887152 0.01882374 0.01887813 0.01882371\n",
      " 0.01999116 0.01885411 0.01882397 0.01882383]\n",
      "n_p_ecg_p_06 [0.01588396 0.01631309 0.01613959 0.01588572 0.01623551 0.01588536\n",
      " 0.02063907 0.01611349 0.01588841 0.0158868 ]\n",
      "n_p_ecg_p_07 [0.06000044 0.06024368 0.06016548 0.06000104 0.06021378 0.06000086\n",
      " 0.06430876 0.06011593 0.06000219 0.0600015 ]\n",
      "n_p_ecg_p_10 [0.02000008 0.02009639 0.02006136 0.02000021 0.02017619 0.02000017\n",
      " 0.02217175 0.02003283 0.02000052 0.02000034]\n",
      "n_p_ecg_p_11 [0.01647736 0.01695366 0.0169835  0.01648335 0.01700849 0.01648199\n",
      " 0.02147382 0.01687408 0.01649132 0.01648689]\n",
      "n_p_ecg_p_12 [0.04588246 0.04598846 0.04596328 0.04588262 0.04603918 0.04588255\n",
      " 0.04836836 0.04592184 0.0458831  0.04588281]\n",
      "fibr_ter_03 [0.04       0.04000649 0.04000594 0.04000001 0.04000532 0.04000001\n",
      " 0.04052386 0.0400039  0.04000002]\n",
      "GIPER_NA [0.01764706 0.01765853 0.01765598 0.01764707 0.01767204 0.0183573\n",
      " 0.01765162 0.01764709 0.01764708]\n",
      "NA_BLOOD [136.60365 136.6038  136.60373 136.60376 136.61949]\n",
      "ALT_BLOOD [0.47570124 0.47587737 0.47575903 0.47570127 0.47583738 0.48039863\n",
      " 0.4757424  0.47570145 0.47570133]\n",
      "AST_BLOOD [0.25876117 0.2588027  0.2587824  0.2587612  0.25879523 0.26037076\n",
      " 0.2587779  0.25876126 0.25876123]\n",
      "L_BLOOD [8.737515 8.739736 8.739271 8.737522 8.740168 8.73752  8.787351 8.738888\n",
      " 8.737532 8.737526]\n",
      "ROE [13.525304 13.531178 13.530332 13.525319 13.53033  13.525313 13.658932\n",
      " 13.528406 13.525348 13.525331]\n",
      "TIME_B_S [4.7382355 4.7382894 4.738268  4.7382865 4.7433896 4.7382526]\n",
      "R_AB_1_n [0.3147642  0.33129433 0.319172   0.3148162  0.3257705  0.31481254\n",
      " 0.40146783 0.31964603 0.31486672 0.3148365 ]\n",
      "R_AB_2_n [0.13652629 0.14676358 0.14064096 0.1365735  0.15034884 0.13655686\n",
      " 0.19025895 0.1390205  0.13665354 0.13661015]\n",
      "R_AB_3_n [0.07178321 0.07451387 0.07355691 0.07180008 0.07667983 0.07179289\n",
      " 0.09347042 0.07274412 0.07183341 0.0718155 ]\n",
      "NITR_S [0.11477749 0.11872265 0.1180552  0.11483168 0.1215165  0.11482801\n",
      " 0.14373685 0.11778483 0.11488318 0.114852  ]\n",
      "NA_R_1_n [0.48365945 0.50876373 0.4910978  0.48376456 0.49991634 0.48374522\n",
      " 0.59300643 0.49045178 0.48388535 0.4838193 ]\n",
      "NA_R_2_n [0.08883181 0.09391403 0.09012067 0.0888407  0.09362659 0.08883887\n",
      " 0.12280085 0.08988778 0.08885337 0.08884598]\n",
      "NA_R_3_n [0.05412362 0.05709951 0.05505872 0.05412992 0.05773159 0.05412791\n",
      " 0.07653768 0.05475583 0.05414122 0.05413475]\n",
      "NOT_NA_1_n [0.33180416 0.33832267 0.33521116 0.3318399  0.34001243 0.33183053\n",
      " 0.3819154  0.33424717 0.33189318 0.3318631 ]\n",
      "NOT_NA_2_n [0.10707735 0.11206584 0.10922446 0.10709519 0.11470255 0.10708861\n",
      " 0.1418453  0.10833428 0.10713018 0.10711004]\n",
      "NOT_NA_3_n [0.07824305 0.08091526 0.07935113 0.07825124 0.08104165 0.07824978\n",
      " 0.10313424 0.07916167 0.0782614  0.0782557 ]\n",
      "LID_S_n [0.28294683 0.2844511  0.2839169  0.28295296 0.28455687 0.28295088\n",
      " 0.3002156  0.28361216 0.28296432 0.28295794]\n",
      "B_BLOK_S_n [0.12647063 0.12669846 0.12653199 0.1264707  0.1266867  0.12647067\n",
      " 0.13184057 0.12651831 0.12647085 0.12647077]\n",
      "ANT_CA_S_n [0.6676474  0.6680073  0.6678531  0.6676481  0.6678905  0.6676479\n",
      " 0.67461705 0.6677789  0.66764927 0.66764855]\n",
      "GEPAR_S_n [0.7152946  0.7154717  0.71550965 0.71529526 0.71553254 0.7152951\n",
      " 0.7205643  0.7154516  0.71529645 0.71529573]\n",
      "ASP_S_n [0.74470586 0.74471295 0.7447185  0.74471796 0.7447059  0.7455358\n",
      " 0.7447125 ]\n",
      "TIKL_S_n [0.01764708 0.01766647 0.01767261 0.01764713 0.01766755 0.01764712\n",
      " 0.01848576 0.01766602 0.01764722 0.01764718]\n",
      "TRENT_S_n [0.20058964 0.20087409 0.20094822 0.20059143 0.20095995 0.20059106\n",
      " 0.20700115 0.20085245 0.20059401 0.20059252]\n"
     ]
    }
   ],
   "source": [
    "#값 분포 확인\n",
    "for column in new_samples_df.columns:\n",
    "    unique_values = new_samples_df[column].dropna().unique()\n",
    "    print(column, unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([data, new_samples_df], ignore_index=True)\n",
    "combined_df = combined_df.drop(columns=['Unnamed: 0'])\n",
    "combined_df.to_csv('1_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape ((1700, 69), (1700,))\n",
      "Resampled dataset shape ((3382, 69), (3382,))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "x = pd.read_csv('./data/3.remove_unbalance_missing_corr_data/1_1.csv')\n",
    "y = pd.read_csv('./data/0.origin_data/target.csv')\n",
    "y = y['LET_IS']\n",
    "\n",
    "sampling_strategy = {label: count * 2 for label, count in Counter(y).items()}\n",
    "ada = ADASYN(random_state=42, sampling_strategy=sampling_strategy)\n",
    "X_res, y_res = ada.fit_resample(x, y)\n",
    "\n",
    "print(f'Original dataset shape {x.shape, y.shape}')\n",
    "print(f'Resampled dataset shape {X_res.shape, y_res.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX is balanced. 1856 1526\n",
      "SIM_GIPERT is balanced. 3322 60\n",
      "nr_11 is balanced. 3340 42\n",
      "nr_02 is unbalanced. 3363 19\n",
      "nr_03 is balanced. 3347 35\n",
      "nr_04 is unbalanced. 3353 29\n",
      "endocr_01 is balanced. 3084 298\n",
      "endocr_02 is balanced. 3340 42\n",
      "zab_leg_01 is balanced. 3247 135\n",
      "zab_leg_02 is balanced. 3197 185\n",
      "zab_leg_03 is balanced. 3344 38\n",
      "zab_leg_06 is unbalanced. 3360 22\n",
      "O_L_POST is balanced. 3271 111\n",
      "K_SH_POST is balanced. 3332 50\n",
      "MP_TP_POST is balanced. 3266 116\n",
      "IM_PG_P is balanced. 3332 50\n",
      "ritm_ecg_p_01 is balanced. 1517 1865\n",
      "ritm_ecg_p_04 is unbalanced. 3359 23\n",
      "ritm_ecg_p_08 is balanced. 3336 46\n",
      "n_r_ecg_p_01 is balanced. 3324 58\n",
      "n_r_ecg_p_03 is balanced. 3171 211\n",
      "n_r_ecg_p_04 is balanced. 3310 72\n",
      "n_r_ecg_p_05 is balanced. 3312 70\n",
      "n_r_ecg_p_06 is unbalanced. 3350 32\n",
      "n_p_ecg_p_03 is unbalanced. 3349 33\n",
      "n_p_ecg_p_06 is unbalanced. 3354 28\n",
      "n_p_ecg_p_07 is balanced. 3277 105\n",
      "n_p_ecg_p_10 is balanced. 3348 34\n",
      "n_p_ecg_p_11 is unbalanced. 3354 28\n",
      "n_p_ecg_p_12 is balanced. 3300 82\n",
      "fibr_ter_03 is balanced. 3314 68\n",
      "GIPO_K is balanced. 2233 1149\n",
      "GIPER_NA is unbalanced. 3352 30\n",
      "NITR_S is balanced. 3160 222\n",
      "LID_S_n is balanced. 2877 505\n",
      "B_BLOK_S_n is balanced. 3165 217\n",
      "ANT_CA_S_n is balanced. 1540 1842\n",
      "GEPAR_S_n is balanced. 1443 1939\n",
      "ASP_S_n is balanced. 1249 2133\n",
      "TIKL_S_n is unbalanced. 3352 30\n",
      "TRENT_S_n is balanced. 3032 350\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#값 분포 확인\n",
    "\n",
    "binary_column_info = {}\n",
    "cnt = 0\n",
    "for column in X_res.columns:\n",
    "    unique_values = X_res[column].dropna().unique()\n",
    "    if set(unique_values) <= {0, 1}:\n",
    "        count_0 = (X_res[column] == 0).sum()\n",
    "        count_1 = (X_res[column] == 1).sum()\n",
    "        total_count = count_0 + count_1\n",
    "        percent_0 = (count_0 / total_count) * 100\n",
    "        percent_1 = (count_1 / total_count) * 100\n",
    "        binary_column_info[column] = {\n",
    "            '0 count': count_0, \n",
    "            '1 count': count_1,\n",
    "            '0 percent': percent_0,\n",
    "            '1 percent': percent_1\n",
    "        }\n",
    "li = []\n",
    "for column, counts in binary_column_info.items():\n",
    "\n",
    "    if(counts['1 percent'] <= 1):\n",
    "        print(column, \"is unbalanced.\", counts['0 count'], counts['1 count'])\n",
    "        cnt +=1\n",
    "        li.append(column)\n",
    "    else:\n",
    "        print(column, \"is balanced.\", counts['0 count'], counts['1 count'])\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res['AGE'] = X_res['AGE'].round().astype(int)\n",
    "X_res.to_csv('./data/3.remove_unbalance_missing_corr_data/1_3.csv')\n",
    "y_res.to_csv('./data/3.remove_unbalance_missing_corr_data/1_3y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape ((1700, 69), (1700,))\n",
      "Resampled dataset shape ((3400, 69), (3400,))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "x = pd.read_csv('./data/3.remove_unbalance_missing_corr_data/1_1.csv')\n",
    "y = pd.read_csv('./data/0.origin_data/target.csv')\n",
    "y = y['LET_IS']\n",
    "\n",
    "# 샘플링 전략 정의\n",
    "sampling_strategy = {label: count * 2 for label, count in Counter(y).items()}\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42, sampling_strategy=sampling_strategy)\n",
    "X_res, y_res = smote.fit_resample(x, y)\n",
    "\n",
    "# 원본 및 리샘플링된 데이터셋의 형태 출력\n",
    "print(f'Original dataset shape {x.shape, y.shape}')\n",
    "print(f'Resampled dataset shape {X_res.shape, y_res.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX is balanced. 1629 1771\n",
      "SIM_GIPERT is balanced. 3340 60\n",
      "nr_11 is balanced. 3356 44\n",
      "nr_02 is unbalanced. 3381 19\n",
      "nr_03 is balanced. 3365 35\n",
      "nr_04 is unbalanced. 3370 30\n",
      "endocr_01 is balanced. 3133 267\n",
      "endocr_02 is balanced. 3358 42\n",
      "zab_leg_01 is balanced. 3243 157\n",
      "zab_leg_02 is balanced. 3264 136\n",
      "zab_leg_03 is balanced. 3360 40\n",
      "zab_leg_06 is unbalanced. 3377 23\n",
      "O_L_POST is balanced. 3275 125\n",
      "K_SH_POST is balanced. 3325 75\n",
      "MP_TP_POST is balanced. 3278 122\n",
      "IM_PG_P is balanced. 3348 52\n",
      "ritm_ecg_p_01 is balanced. 1446 1954\n",
      "ritm_ecg_p_04 is unbalanced. 3377 23\n",
      "ritm_ecg_p_08 is balanced. 3354 46\n",
      "n_r_ecg_p_01 is balanced. 3340 60\n",
      "n_r_ecg_p_03 is balanced. 3179 221\n",
      "n_r_ecg_p_04 is balanced. 3328 72\n",
      "n_r_ecg_p_05 is balanced. 3324 76\n",
      "n_r_ecg_p_06 is unbalanced. 3366 34\n",
      "n_p_ecg_p_03 is balanced. 3364 36\n",
      "n_p_ecg_p_06 is unbalanced. 3372 28\n",
      "n_p_ecg_p_07 is balanced. 3294 106\n",
      "n_p_ecg_p_10 is unbalanced. 3366 34\n",
      "n_p_ecg_p_11 is unbalanced. 3371 29\n",
      "n_p_ecg_p_12 is balanced. 3311 89\n",
      "fibr_ter_03 is balanced. 3322 78\n",
      "GIPO_K is balanced. 2440 960\n",
      "GIPER_NA is unbalanced. 3368 32\n",
      "NITR_S is balanced. 3173 227\n",
      "LID_S_n is balanced. 2765 635\n",
      "B_BLOK_S_n is balanced. 3152 248\n",
      "ANT_CA_S_n is balanced. 1499 1901\n",
      "GEPAR_S_n is balanced. 1285 2115\n",
      "ASP_S_n is balanced. 1177 2223\n",
      "TIKL_S_n is unbalanced. 3368 32\n",
      "TRENT_S_n is balanced. 2965 435\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#값 분포 확인\n",
    "binary_column_info = {}\n",
    "cnt = 0\n",
    "for column in X_res.columns:\n",
    "    unique_values = X_res[column].dropna().unique()\n",
    "    if set(unique_values) <= {0, 1}:\n",
    "        count_0 = (X_res[column] == 0).sum()\n",
    "        count_1 = (X_res[column] == 1).sum()\n",
    "        total_count = count_0 + count_1\n",
    "        percent_0 = (count_0 / total_count) * 100\n",
    "        percent_1 = (count_1 / total_count) * 100\n",
    "        binary_column_info[column] = {\n",
    "            '0 count': count_0, \n",
    "            '1 count': count_1,\n",
    "            '0 percent': percent_0,\n",
    "            '1 percent': percent_1\n",
    "        }\n",
    "li = []\n",
    "for column, counts in binary_column_info.items():\n",
    "\n",
    "    if(counts['1 percent'] <= 1):\n",
    "        print(column, \"is unbalanced.\", counts['0 count'], counts['1 count'])\n",
    "        cnt +=1\n",
    "        li.append(column)\n",
    "    else:\n",
    "        print(column, \"is balanced.\", counts['0 count'], counts['1 count'])\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res['AGE'] = X_res['AGE'].round().astype(int)\n",
    "X_res.tail()\n",
    "X_res.to_csv('./data/3.remove_unbalance_missing_corr_data/1_4.csv')\n",
    "y_res.to_csv('./data/3.remove_unbalance_missing_corr_data/1_4y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Border-SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape ((1700, 69), (1700,))\n",
      "Resampled dataset shape ((3400, 69), (3400,))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터 로드\n",
    "x = pd.read_csv('./data/3.remove_unbalance_missing_corr_data/1_1.csv')\n",
    "y = pd.read_csv('./data/0.origin_data/target.csv')\n",
    "y = y['LET_IS']\n",
    "\n",
    "# 샘플링 전략 정의\n",
    "sampling_strategy = {label: count * 2 for label, count in Counter(y).items()}\n",
    "\n",
    "# Borderline SMOTE 적용\n",
    "borderline_smote = BorderlineSMOTE(random_state=42, sampling_strategy=sampling_strategy)\n",
    "X_res, y_res = borderline_smote.fit_resample(x, y)\n",
    "\n",
    "# 원본 및 리샘플링된 데이터셋의 형태 출력\n",
    "print(f'Original dataset shape {x.shape, y.shape}')\n",
    "print(f'Resampled dataset shape {X_res.shape, y_res.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX is balanced. 1664 1736\n",
      "SIM_GIPERT is balanced. 3341 59\n",
      "nr_11 is balanced. 3358 42\n",
      "nr_02 is unbalanced. 3381 19\n",
      "nr_03 is balanced. 3365 35\n",
      "nr_04 is unbalanced. 3369 31\n",
      "endocr_01 is balanced. 3153 247\n",
      "endocr_02 is balanced. 3358 42\n",
      "zab_leg_01 is balanced. 3263 137\n",
      "zab_leg_02 is balanced. 3276 124\n",
      "zab_leg_03 is balanced. 3363 37\n",
      "zab_leg_06 is unbalanced. 3378 22\n",
      "O_L_POST is balanced. 3281 119\n",
      "K_SH_POST is balanced. 3351 49\n",
      "MP_TP_POST is balanced. 3280 120\n",
      "IM_PG_P is balanced. 3348 52\n",
      "ritm_ecg_p_01 is balanced. 1228 2172\n",
      "ritm_ecg_p_04 is unbalanced. 3377 23\n",
      "ritm_ecg_p_08 is balanced. 3354 46\n",
      "n_r_ecg_p_01 is balanced. 3340 60\n",
      "n_r_ecg_p_03 is balanced. 3191 209\n",
      "n_r_ecg_p_04 is balanced. 3331 69\n",
      "n_r_ecg_p_05 is balanced. 3325 75\n",
      "n_r_ecg_p_06 is unbalanced. 3368 32\n",
      "n_p_ecg_p_03 is unbalanced. 3368 32\n",
      "n_p_ecg_p_06 is unbalanced. 3372 28\n",
      "n_p_ecg_p_07 is balanced. 3296 104\n",
      "n_p_ecg_p_10 is unbalanced. 3366 34\n",
      "n_p_ecg_p_11 is unbalanced. 3372 28\n",
      "n_p_ecg_p_12 is balanced. 3321 79\n",
      "fibr_ter_03 is balanced. 3331 69\n",
      "GIPO_K is balanced. 2133 1267\n",
      "GIPER_NA is unbalanced. 3370 30\n",
      "NITR_S is balanced. 3171 229\n",
      "LID_S_n is balanced. 2893 507\n",
      "B_BLOK_S_n is balanced. 3185 215\n",
      "ANT_CA_S_n is balanced. 1401 1999\n",
      "GEPAR_S_n is balanced. 1578 1822\n",
      "ASP_S_n is balanced. 1248 2152\n",
      "TIKL_S_n is unbalanced. 3370 30\n",
      "TRENT_S_n is balanced. 3042 358\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "#값 분포 확인\n",
    "binary_column_info = {}\n",
    "cnt = 0\n",
    "for column in X_res.columns:\n",
    "    unique_values = X_res[column].dropna().unique()\n",
    "    if set(unique_values) <= {0, 1}:\n",
    "        count_0 = (X_res[column] == 0).sum()\n",
    "        count_1 = (X_res[column] == 1).sum()\n",
    "        total_count = count_0 + count_1\n",
    "        percent_0 = (count_0 / total_count) * 100\n",
    "        percent_1 = (count_1 / total_count) * 100\n",
    "        binary_column_info[column] = {\n",
    "            '0 count': count_0, \n",
    "            '1 count': count_1,\n",
    "            '0 percent': percent_0,\n",
    "            '1 percent': percent_1\n",
    "        }\n",
    "li = []\n",
    "for column, counts in binary_column_info.items():\n",
    "\n",
    "    if(counts['1 percent'] <= 1):\n",
    "        print(column, \"is unbalanced.\", counts['0 count'], counts['1 count'])\n",
    "        cnt +=1\n",
    "        li.append(column)\n",
    "    else:\n",
    "        print(column, \"is balanced.\", counts['0 count'], counts['1 count'])\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res['AGE'] = X_res['AGE'].round().astype(int)\n",
    "X_res.tail()\n",
    "X_res.to_csv('./data/3.remove_unbalance_missing_corr_data/1_5.csv')\n",
    "y_res.to_csv('./data/3.remove_unbalance_missing_corr_data/1_5y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape ((1700, 69), (1700,))\n",
      "Resampled dataset shape ((3353, 69), (3353,))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터 로드\n",
    "x = pd.read_csv('./data/3.remove_unbalance_missing_corr_data/1_1.csv')\n",
    "y = pd.read_csv('./data/0.origin_data/target.csv')\n",
    "y = y['LET_IS']\n",
    "\n",
    "# 증강 전략 설정: 원본 데이터의 2배로 증강\n",
    "sampling_strategy = {label: count * 2 for label, count in Counter(y).items()}\n",
    "\n",
    "# SVMSMOTE 적용\n",
    "svm_smote = SVMSMOTE(random_state=42, sampling_strategy=sampling_strategy)\n",
    "X_res, y_res = svm_smote.fit_resample(x, y)\n",
    "\n",
    "print(f'Original dataset shape {x.shape, y.shape}')\n",
    "print(f'Resampled dataset shape {X_res.shape, y_res.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEX is balanced. 1574 1779\n",
      "SIM_GIPERT is balanced. 3270 83\n",
      "nr_11 is balanced. 3296 57\n",
      "nr_02 is unbalanced. 3334 19\n",
      "nr_03 is balanced. 3317 36\n",
      "nr_04 is unbalanced. 3322 31\n",
      "endocr_01 is balanced. 2973 380\n",
      "endocr_02 is balanced. 3284 69\n",
      "zab_leg_01 is balanced. 3216 137\n",
      "zab_leg_02 is balanced. 3169 184\n",
      "zab_leg_03 is balanced. 3294 59\n",
      "zab_leg_06 is balanced. 3317 36\n",
      "O_L_POST is balanced. 3228 125\n",
      "K_SH_POST is balanced. 3246 107\n",
      "MP_TP_POST is balanced. 3205 148\n",
      "IM_PG_P is balanced. 3282 71\n",
      "ritm_ecg_p_01 is balanced. 1092 2261\n",
      "ritm_ecg_p_04 is balanced. 3310 43\n",
      "ritm_ecg_p_08 is balanced. 3264 89\n",
      "n_r_ecg_p_01 is balanced. 3292 61\n",
      "n_r_ecg_p_03 is balanced. 3127 226\n",
      "n_r_ecg_p_04 is balanced. 3278 75\n",
      "n_r_ecg_p_05 is balanced. 3254 99\n",
      "n_r_ecg_p_06 is balanced. 3318 35\n",
      "n_p_ecg_p_03 is balanced. 3292 61\n",
      "n_p_ecg_p_06 is balanced. 3302 51\n",
      "n_p_ecg_p_07 is balanced. 3205 148\n",
      "n_p_ecg_p_10 is balanced. 3317 36\n",
      "n_p_ecg_p_11 is balanced. 3313 40\n",
      "n_p_ecg_p_12 is balanced. 3267 86\n",
      "fibr_ter_03 is balanced. 3215 138\n",
      "GIPO_K is balanced. 2044 1309\n",
      "GIPER_NA is balanced. 3308 45\n",
      "NITR_S is balanced. 2994 359\n",
      "LID_S_n is balanced. 2738 615\n",
      "B_BLOK_S_n is balanced. 3089 264\n",
      "ANT_CA_S_n is balanced. 1380 1973\n",
      "GEPAR_S_n is balanced. 1172 2181\n",
      "ASP_S_n is balanced. 1019 2334\n",
      "TIKL_S_n is balanced. 3311 42\n",
      "TRENT_S_n is balanced. 2925 428\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#값 분포 확인\n",
    "binary_column_info = {}\n",
    "cnt = 0\n",
    "for column in X_res.columns:\n",
    "    unique_values = X_res[column].dropna().unique()\n",
    "    if set(unique_values) <= {0, 1}:\n",
    "        count_0 = (X_res[column] == 0).sum()\n",
    "        count_1 = (X_res[column] == 1).sum()\n",
    "        total_count = count_0 + count_1\n",
    "        percent_0 = (count_0 / total_count) * 100\n",
    "        percent_1 = (count_1 / total_count) * 100\n",
    "        binary_column_info[column] = {\n",
    "            '0 count': count_0, \n",
    "            '1 count': count_1,\n",
    "            '0 percent': percent_0,\n",
    "            '1 percent': percent_1\n",
    "        }\n",
    "li = []\n",
    "for column, counts in binary_column_info.items():\n",
    "\n",
    "    if(counts['1 percent'] <= 1):\n",
    "        print(column, \"is unbalanced.\", counts['0 count'], counts['1 count'])\n",
    "        cnt +=1\n",
    "        li.append(column)\n",
    "    else:\n",
    "        print(column, \"is balanced.\", counts['0 count'], counts['1 count'])\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res['AGE'] = X_res['AGE'].round().astype(int)\n",
    "X_res.tail()\n",
    "X_res.to_csv('./data/3.remove_unbalance_missing_corr_data/1_6.csv')\n",
    "y_res.to_csv('./data/3.remove_unbalance_missing_corr_data/1_6y.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
