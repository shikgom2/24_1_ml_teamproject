{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minMax + one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['Unnamed: 0.1', 'AGE', 'S_AD_ORIT', 'D_AD_ORIT', 'K_BLOOD', 'NA_BLOOD', 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE']\n",
      "Categorical Variables: ['INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A', 'ant_im', 'lat_im', 'inf_im', 'post_im', 'TIME_B_S', 'R_AB_1_n', 'R_AB_2_n', 'R_AB_3_n', 'NA_R_1_n', 'NA_R_2_n', 'NA_R_3_n', 'NOT_NA_1_n', 'NOT_NA_2_n', 'NOT_NA_3_n']\n",
      "Binary Variables: ['SEX', 'SIM_GIPERT', 'nr_11', 'nr_02', 'nr_03', 'nr_04', 'endocr_01', 'endocr_02', 'zab_leg_01', 'zab_leg_02', 'zab_leg_03', 'zab_leg_06', 'O_L_POST', 'K_SH_POST', 'MP_TP_POST', 'IM_PG_P', 'ritm_ecg_p_01', 'ritm_ecg_p_02', 'ritm_ecg_p_04', 'ritm_ecg_p_07', 'ritm_ecg_p_08', 'n_r_ecg_p_01', 'n_r_ecg_p_03', 'n_r_ecg_p_04', 'n_r_ecg_p_05', 'n_r_ecg_p_06', 'n_p_ecg_p_03', 'n_p_ecg_p_06', 'n_p_ecg_p_07', 'n_p_ecg_p_10', 'n_p_ecg_p_11', 'n_p_ecg_p_12', 'fibr_ter_03', 'GIPO_K', 'GIPER_NA', 'NITR_S', 'LID_S_n', 'B_BLOK_S_n', 'ANT_CA_S_n', 'GEPAR_S_n', 'ASP_S_n', 'TIKL_S_n', 'TRENT_S_n']\n",
      "Transformed Data Shape: (3400, 133)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './rawdata/1_1.csv'  # 파일 경로를 적절히 수정하세요\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Removing the potential index column 'Unnamed: 0' for clarity\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Identifying types of variables\n",
    "continuous_vars = []\n",
    "categorical_vars = []\n",
    "binary_vars = []\n",
    "\n",
    "for column in data.columns:\n",
    "    unique_values = data[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        binary_vars.append(column)\n",
    "    elif unique_values <= 10:\n",
    "        categorical_vars.append(column)\n",
    "    else:\n",
    "        continuous_vars.append(column)\n",
    "\n",
    "# Print the identified variables\n",
    "print(\"Continuous Variables:\", continuous_vars)\n",
    "print(\"Categorical Variables:\", categorical_vars)\n",
    "print(\"Binary Variables:\", binary_vars)\n",
    "\n",
    "# Apply MinMaxScaler to continuous variables\n",
    "scaler = MinMaxScaler()\n",
    "data[continuous_vars] = scaler.fit_transform(data[continuous_vars])\n",
    "\n",
    "# Apply OneHotEncoder to categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' to avoid multicollinearity\n",
    "encoded_categorical_data = encoder.fit_transform(data[categorical_vars])\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical_data, columns=encoder.get_feature_names_out(categorical_vars))\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded columns\n",
    "data = data.drop(columns=categorical_vars)\n",
    "data = pd.concat([data, encoded_categorical_df], axis=1)\n",
    "\n",
    "# check after transformed data shape\n",
    "print(\"Transformed Data Shape:\", data.shape)\n",
    "\n",
    "# If you want to save the transformed dataframe to a new CSV file\n",
    "output_path = './2-minmax_onehot_1_5.csv'  # 파일 저장 경로를 적절히 수정하세요\n",
    "data.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minMax + label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['AGE', 'S_AD_ORIT', 'D_AD_ORIT', 'K_BLOOD', 'NA_BLOOD', 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE']\n",
      "Categorical Variables: ['INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A', 'ant_im', 'lat_im', 'inf_im', 'post_im', 'TIME_B_S', 'R_AB_1_n', 'R_AB_2_n', 'R_AB_3_n', 'NA_R_1_n', 'NA_R_2_n', 'NA_R_3_n', 'NOT_NA_1_n', 'NOT_NA_2_n', 'NOT_NA_3_n']\n",
      "Binary Variables: ['SEX', 'SIM_GIPERT', 'nr_11', 'nr_02', 'nr_03', 'nr_04', 'endocr_01', 'endocr_02', 'zab_leg_01', 'zab_leg_02', 'zab_leg_03', 'zab_leg_06', 'O_L_POST', 'K_SH_POST', 'MP_TP_POST', 'IM_PG_P', 'ritm_ecg_p_01', 'ritm_ecg_p_02', 'ritm_ecg_p_04', 'ritm_ecg_p_07', 'ritm_ecg_p_08', 'n_r_ecg_p_01', 'n_r_ecg_p_03', 'n_r_ecg_p_04', 'n_r_ecg_p_05', 'n_r_ecg_p_06', 'n_p_ecg_p_03', 'n_p_ecg_p_06', 'n_p_ecg_p_07', 'n_p_ecg_p_10', 'n_p_ecg_p_11', 'n_p_ecg_p_12', 'fibr_ter_03', 'GIPO_K', 'GIPER_NA', 'NITR_S', 'LID_S_n', 'B_BLOK_S_n', 'ANT_CA_S_n', 'GEPAR_S_n', 'ASP_S_n', 'TIKL_S_n', 'TRENT_S_n']\n",
      "Transformed Data Shape: (1700, 73)\n",
      "Unique values in INF_ANAM after label encoding: [2 1 0 3]\n",
      "Unique values in STENOK_AN after label encoding: [1 0 6 5 2 3 4]\n",
      "Unique values in FK_STENOK after label encoding: [1 0 2 3 4]\n",
      "Unique values in IBS_POST after label encoding: [2 0 1]\n",
      "Unique values in GB after label encoding: [3 0 2 1]\n",
      "Unique values in DLIT_AG after label encoding: [7 0 2 3 6 1 5 4]\n",
      "Unique values in ZSN_A after label encoding: [0 1 2 3 4]\n",
      "Unique values in ant_im after label encoding: [1 4 0 2 3]\n",
      "Unique values in lat_im after label encoding: [0 1 2 3 4]\n",
      "Unique values in inf_im after label encoding: [0 1 3 2 4]\n",
      "Unique values in post_im after label encoding: [0 2 1 3 4]\n",
      "Unique values in TIME_B_S after label encoding: [3 1 2 8 0 6 4 7 5]\n",
      "Unique values in R_AB_1_n after label encoding: [0 3 2 1]\n",
      "Unique values in R_AB_2_n after label encoding: [0 1 2 3]\n",
      "Unique values in R_AB_3_n after label encoding: [1 0 2 3]\n",
      "Unique values in NA_R_1_n after label encoding: [0 1 2 3 4]\n",
      "Unique values in NA_R_2_n after label encoding: [0 1 2 3]\n",
      "Unique values in NA_R_3_n after label encoding: [0 2 1]\n",
      "Unique values in NOT_NA_1_n after label encoding: [0 1 3 2 4]\n",
      "Unique values in NOT_NA_2_n after label encoding: [0 2 1 3]\n",
      "Unique values in NOT_NA_3_n after label encoding: [0 2 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './rawdata/1_1.csv'  # Adjust the file path as needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Removing the potential index column 'Unnamed: 0' for clarity\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Identifying types of variables\n",
    "continuous_vars = []\n",
    "categorical_vars = []\n",
    "binary_vars = []\n",
    "\n",
    "for column in data.columns:\n",
    "    unique_values = data[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        binary_vars.append(column)\n",
    "    elif unique_values <= 10:\n",
    "        categorical_vars.append(column)\n",
    "    else:\n",
    "        continuous_vars.append(column)\n",
    "\n",
    "# Print the identified variables\n",
    "print(\"Continuous Variables:\", continuous_vars)\n",
    "print(\"Categorical Variables:\", categorical_vars)\n",
    "print(\"Binary Variables:\", binary_vars)\n",
    "\n",
    "# Apply MinMaxScaler to continuous variables\n",
    "scaler = MinMaxScaler()\n",
    "data[continuous_vars] = scaler.fit_transform(data[continuous_vars])\n",
    "\n",
    "# Apply LabelEncoder to categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_vars:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "\n",
    "# Check the shape of the transformed dataframe\n",
    "print(\"Transformed Data Shape:\", data.shape)\n",
    "\n",
    "# Verify label encoding by checking unique values in one of the categorical columns\n",
    "for column in categorical_vars:\n",
    "    print(f\"Unique values in {column} after label encoding: {data[column].unique()}\")\n",
    "\n",
    "# If you want to save the transformed dataframe to a new CSV file\n",
    "output_path = './preprocessed_data/2-minmax_label_1_1.csv'  # Adjust the file save path as needed\n",
    "data.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only minMax, not (categorical preprocesseing) included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['AGE', 'S_AD_ORIT', 'D_AD_ORIT', 'K_BLOOD', 'NA_BLOOD', 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE']\n",
      "Categorical Variables: ['INF_ANAM', 'STENOK_AN', 'FK_STENOK', 'IBS_POST', 'GB', 'DLIT_AG', 'ZSN_A', 'ant_im', 'lat_im', 'inf_im', 'post_im', 'TIME_B_S', 'R_AB_1_n', 'R_AB_2_n', 'R_AB_3_n', 'NA_R_1_n', 'NA_R_2_n', 'NA_R_3_n', 'NOT_NA_1_n', 'NOT_NA_2_n', 'NOT_NA_3_n']\n",
      "Binary Variables: ['SEX', 'SIM_GIPERT', 'nr_11', 'nr_02', 'nr_03', 'nr_04', 'endocr_01', 'endocr_02', 'zab_leg_01', 'zab_leg_02', 'zab_leg_03', 'zab_leg_06', 'O_L_POST', 'K_SH_POST', 'MP_TP_POST', 'IM_PG_P', 'ritm_ecg_p_01', 'ritm_ecg_p_02', 'ritm_ecg_p_04', 'ritm_ecg_p_07', 'ritm_ecg_p_08', 'n_r_ecg_p_01', 'n_r_ecg_p_03', 'n_r_ecg_p_04', 'n_r_ecg_p_05', 'n_r_ecg_p_06', 'n_p_ecg_p_03', 'n_p_ecg_p_06', 'n_p_ecg_p_07', 'n_p_ecg_p_10', 'n_p_ecg_p_11', 'n_p_ecg_p_12', 'fibr_ter_03', 'GIPO_K', 'GIPER_NA', 'NITR_S', 'LID_S_n', 'B_BLOK_S_n', 'ANT_CA_S_n', 'GEPAR_S_n', 'ASP_S_n', 'TIKL_S_n', 'TRENT_S_n']\n",
      "Transformed Data Shape: (1700, 73)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './rawdata/1_1.csv'  # Adjust the file path as needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Removing the potential index column 'Unnamed: 0' for clarity\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Identifying types of variables\n",
    "continuous_vars = []\n",
    "categorical_vars = []\n",
    "binary_vars = []\n",
    "\n",
    "for column in data.columns:\n",
    "    unique_values = data[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        binary_vars.append(column)\n",
    "    elif unique_values <= 10:\n",
    "        categorical_vars.append(column)\n",
    "    else:\n",
    "        continuous_vars.append(column)\n",
    "\n",
    "# Print the identified variables\n",
    "print(\"Continuous Variables:\", continuous_vars)\n",
    "print(\"Categorical Variables:\", categorical_vars)\n",
    "print(\"Binary Variables:\", binary_vars)\n",
    "\n",
    "# Apply MinMaxScaler to continuous variables\n",
    "scaler = MinMaxScaler()\n",
    "data[continuous_vars] = scaler.fit_transform(data[continuous_vars])\n",
    "\n",
    "# Categorical variables are left in their original form\n",
    "# Concatenate the data to ensure we have the continuous and original categorical variables\n",
    "\n",
    "# Drop the original categorical columns if needed to avoid redundancy\n",
    "# In this case, it's not necessary since we're not encoding them\n",
    "\n",
    "# Ensure binary variables remain unchanged\n",
    "# They should already be in an appropriate form (0 and 1)\n",
    "\n",
    "# Final check for the transformed data shape and contents\n",
    "print(\"Transformed Data Shape:\", data.shape)\n",
    "\n",
    "# If you want to save the transformed dataframe to a new CSV file\n",
    "output_path = './preprocessed_data/2-minmax_no_encoding_1_1.csv'  # Adjust the file save path as needed\n",
    "data.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
