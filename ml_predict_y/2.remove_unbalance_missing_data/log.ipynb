{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOG + ONEHOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['AGE', 'NA_BLOOD', 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE']\n",
      "Categorical Variables: ['INF_ANAM', 'IBS_POST', 'ZSN_A', 'ant_im', 'lat_im', 'inf_im', 'post_im', 'TIME_B_S', 'R_AB_1_n', 'R_AB_2_n', 'R_AB_3_n', 'NA_R_1_n', 'NA_R_2_n', 'NA_R_3_n', 'NOT_NA_1_n', 'NOT_NA_2_n', 'NOT_NA_3_n']\n",
      "Binary Variables: ['SEX', 'SIM_GIPERT', 'nr_11', 'nr_02', 'nr_03', 'nr_04', 'endocr_01', 'endocr_02', 'zab_leg_01', 'zab_leg_02', 'zab_leg_03', 'zab_leg_06', 'O_L_POST', 'K_SH_POST', 'IM_PG_P', 'ritm_ecg_p_04', 'ritm_ecg_p_08', 'n_r_ecg_p_01', 'n_r_ecg_p_03', 'n_r_ecg_p_04', 'n_r_ecg_p_05', 'n_r_ecg_p_06', 'n_p_ecg_p_03', 'n_p_ecg_p_06', 'n_p_ecg_p_07', 'n_p_ecg_p_10', 'n_p_ecg_p_11', 'n_p_ecg_p_12', 'fibr_ter_03', 'GIPER_NA', 'NITR_S', 'LID_S_n', 'B_BLOK_S_n', 'ANT_CA_S_n', 'GEPAR_S_n', 'ASP_S_n', 'TIKL_S_n', 'TRENT_S_n']\n",
      "Transformed Data Shape: (1700, 104)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './1_1.csv'  # 파일 경로를 적절히 수정하세요\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Removing the potential index column 'Unnamed: 0' for clarity\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Identifying types of variables\n",
    "continuous_vars = []\n",
    "categorical_vars = []\n",
    "binary_vars = []\n",
    "\n",
    "for column in data.columns:\n",
    "    unique_values = data[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        binary_vars.append(column)\n",
    "    elif unique_values <= 10:\n",
    "        categorical_vars.append(column)\n",
    "    else:\n",
    "        continuous_vars.append(column)\n",
    "\n",
    "# Print the identified variables\n",
    "print(\"Continuous Variables:\", continuous_vars)\n",
    "print(\"Categorical Variables:\", categorical_vars)\n",
    "print(\"Binary Variables:\", binary_vars)\n",
    "\n",
    "# Apply LogScaler to continuous variables\n",
    "# Shift values to be positive by adding a constant\n",
    "data[continuous_vars] = data[continuous_vars] + 1\n",
    "# Apply the log transformation\n",
    "data[continuous_vars] = np.log(data[continuous_vars])\n",
    "\n",
    "# Apply OneHotEncoder to categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first')  # drop='first' to avoid multicollinearity\n",
    "encoded_categorical_data = encoder.fit_transform(data[categorical_vars])\n",
    "encoded_categorical_df = pd.DataFrame(encoded_categorical_data, columns=encoder.get_feature_names_out(categorical_vars))\n",
    "\n",
    "# Drop original categorical columns and concatenate encoded columns\n",
    "data = data.drop(columns=categorical_vars)\n",
    "data = pd.concat([data, encoded_categorical_df], axis=1)\n",
    "\n",
    "# check after transformed data shape\n",
    "print(\"Transformed Data Shape:\", data.shape)\n",
    "\n",
    "# If you want to save the transformed dataframe to a new CSV file\n",
    "output_path = './log_onehot_1_1.csv'  # 파일 저장 경로를 적절히 수정하세요\n",
    "data.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOG + LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './1_1.csv'  # 파일 경로를 적절히 수정하세요\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Removing the potential index column 'Unnamed: 0' for clarity\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Identifying types of variables\n",
    "continuous_vars = []\n",
    "categorical_vars = []\n",
    "binary_vars = []\n",
    "\n",
    "for column in data.columns:\n",
    "    unique_values = data[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        binary_vars.append(column)\n",
    "    elif unique_values <= 10:\n",
    "        categorical_vars.append(column)\n",
    "    else:\n",
    "        continuous_vars.append(column)\n",
    "\n",
    "# Print the identified variables\n",
    "print(\"Continuous Variables:\", continuous_vars)\n",
    "print(\"Categorical Variables:\", categorical_vars)\n",
    "print(\"Binary Variables:\", binary_vars)\n",
    "\n",
    "# Apply LogScaler to continuous variables\n",
    "# Shift values to be positive by adding a constant\n",
    "data[continuous_vars] = data[continuous_vars] + 1\n",
    "# Apply the log transformation\n",
    "data[continuous_vars] = np.log(data[continuous_vars])\n",
    "\n",
    "# Apply LabelEncoder to categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_vars:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Display the first few rows of the transformed dataframe\n",
    "print(data.head())\n",
    "\n",
    "# Check the shape of the transformed dataframe\n",
    "print(\"Transformed Data Shape:\", data.shape)\n",
    "\n",
    "# If you want to save the transformed dataframe to a new CSV file\n",
    "output_path = './log_label_1_1.csv'  # 파일 저장 경로를 적절히 수정하세요\n",
    "data.to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
