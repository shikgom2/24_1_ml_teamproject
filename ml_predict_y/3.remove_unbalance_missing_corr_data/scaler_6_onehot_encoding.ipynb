{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Variables: ['AGE', 'S_AD_ORIT', 'K_BLOOD', 'NA_BLOOD', 'ALT_BLOOD', 'AST_BLOOD', 'L_BLOOD', 'ROE']\n",
      "Categorical Variables: ['INF_ANAM', 'STENOK_AN', 'IBS_POST', 'GB', 'ZSN_A', 'ant_im', 'lat_im', 'inf_im', 'post_im', 'TIME_B_S', 'R_AB_1_n', 'R_AB_2_n', 'R_AB_3_n', 'NA_R_1_n', 'NA_R_2_n', 'NA_R_3_n', 'NOT_NA_1_n', 'NOT_NA_2_n', 'NOT_NA_3_n']\n",
      "Binary Variables: ['SEX', 'SIM_GIPERT', 'nr_11', 'nr_02', 'nr_03', 'nr_04', 'endocr_01', 'endocr_02', 'zab_leg_01', 'zab_leg_02', 'zab_leg_03', 'zab_leg_06', 'O_L_POST', 'K_SH_POST', 'MP_TP_POST', 'IM_PG_P', 'ritm_ecg_p_01', 'ritm_ecg_p_04', 'ritm_ecg_p_08', 'n_r_ecg_p_01', 'n_r_ecg_p_03', 'n_r_ecg_p_04', 'n_r_ecg_p_05', 'n_r_ecg_p_06', 'n_p_ecg_p_03', 'n_p_ecg_p_06', 'n_p_ecg_p_07', 'n_p_ecg_p_10', 'n_p_ecg_p_11', 'n_p_ecg_p_12', 'fibr_ter_03', 'GIPO_K', 'GIPER_NA', 'NITR_S', 'LID_S_n', 'B_BLOK_S_n', 'ANT_CA_S_n', 'GEPAR_S_n', 'ASP_S_n', 'TIKL_S_n', 'TRENT_S_n']\n",
      "Data transformed using minmax and saved to ./preprocessed_data/3-minmax_onehot_encoding_1_1.csv\n",
      "Data transformed using robust and saved to ./preprocessed_data/3-robust_onehot_encoding_1_1.csv\n",
      "Data transformed using Log Transformation and saved to ./preprocessed_data/3-log_onehot_encoding_1_1.csv\n",
      "Data transformed using normalize and saved to ./preprocessed_data/3-normalize_onehot_encoding_1_1.csv\n",
      "Data transformed using maxabs and saved to ./preprocessed_data/3-maxabs_onehot_encoding_1_1.csv\n",
      "Data transformed using zscore and saved to ./preprocessed_data/3-zscore_onehot_encoding_1_1.csv\n",
      "Transformation complete for all specified scalers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/83/b6jh2lr54796xh55_hnd7gmr0000gn/T/ipykernel_11689/3524576452.py:51: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  log_data[continuous_vars] = log_data[continuous_vars].applymap(lambda x: np.log(x + 1) if x >= 0 else np.nan)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, Normalizer, MaxAbsScaler, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './rawdata/1_1.csv'  # Adjust the file path as needed\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Removing the potential index column 'Unnamed: 0' for clarity\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Identifying types of variables\n",
    "continuous_vars = []\n",
    "categorical_vars = []\n",
    "binary_vars = []\n",
    "\n",
    "for column in data.columns:\n",
    "    unique_values = data[column].nunique()\n",
    "    if unique_values == 2:\n",
    "        binary_vars.append(column)\n",
    "    elif unique_values <= 10:\n",
    "        categorical_vars.append(column)\n",
    "    else:\n",
    "        continuous_vars.append(column)\n",
    "\n",
    "# Print the identified variables\n",
    "print(\"Continuous Variables:\", continuous_vars)\n",
    "print(\"Categorical Variables:\", categorical_vars)\n",
    "print(\"Binary Variables:\", binary_vars)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "data = pd.get_dummies(data, columns=categorical_vars, drop_first=True)\n",
    "\n",
    "# Function to apply different scalers and save the transformed data\n",
    "def apply_and_save_scaler(scaler, scaler_name, data, continuous_vars):\n",
    "    data_copy = data.copy()\n",
    "    data_copy[continuous_vars] = scaler.fit_transform(data_copy[continuous_vars])\n",
    "    output_path = f'./preprocessed_data/3-{scaler_name}_onehot_encoding_1_1.csv'\n",
    "    data_copy.to_csv(output_path, index=False)\n",
    "    print(f\"Data transformed using {scaler_name} and saved to {output_path}\")\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "apply_and_save_scaler(MinMaxScaler(), \"minmax\", data, continuous_vars)\n",
    "\n",
    "# Apply RobustScaler\n",
    "apply_and_save_scaler(RobustScaler(), \"robust\", data, continuous_vars)\n",
    "\n",
    "# Apply Log Transformation\n",
    "log_data = data.copy()\n",
    "log_data[continuous_vars] = log_data[continuous_vars].applymap(lambda x: np.log(x + 1) if x >= 0 else np.nan)\n",
    "log_data.dropna(inplace=True)  # Drop rows with NaN values resulting from negative inputs\n",
    "log_output_path = './preprocessed_data/3-log_onehot_encoding_1_1.csv'\n",
    "log_data.to_csv(log_output_path, index=False)\n",
    "print(f\"Data transformed using Log Transformation and saved to {log_output_path}\")\n",
    "\n",
    "# Apply Normalizer\n",
    "apply_and_save_scaler(Normalizer(), \"normalize\", data, continuous_vars)\n",
    "\n",
    "# Apply MaxAbsScaler\n",
    "apply_and_save_scaler(MaxAbsScaler(), \"maxabs\", data, continuous_vars)\n",
    "\n",
    "# Apply StandardScaler (Z-score normalization)\n",
    "apply_and_save_scaler(StandardScaler(), \"zscore\", data, continuous_vars)\n",
    "\n",
    "# Final check for the transformed data shapes and contents\n",
    "print(\"Transformation complete for all specified scalers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
